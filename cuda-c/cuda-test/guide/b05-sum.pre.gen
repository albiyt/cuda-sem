# 1 "/home/chathhorn/gitpub/cuda-sem/cuda-c/cuda-test/guide/b05-sum.cu"
# 1 "<built-in>"
# 1 "<command-line>"
# 1 "/home/chathhorn/gitpub/cuda-sem/cuda-c/cuda-test/guide/b05-sum.cu"
// Incomplete
// From Appendix B.5 of the CUDA-C Programming Guide. 

# 1 "/home/chathhorn/proj/cuda-sem/cuda-c/dist/includes/cuda.h" 1


# 1 "/home/chathhorn/proj/cuda-sem/cuda-c/dist/includes/kccSettings.h" 1
# 4 "/home/chathhorn/proj/cuda-sem/cuda-c/dist/includes/cuda.h" 2

enum cudaMemcpyKind {
      cudaMemcpyHostToDevice = 1,
      cudaMemcpyDeviceToHost = 2,
};

typedef enum cudaError {
      cudaSuccess = 0,
      cudaErrorInvalidDevice = 10,
      cudaErrorInvalidResourceHandle = 33,
      cudaErrorNotReady = 34,
      cudaErrorPeerAccessNotEnabled = 50,
} cudaError_t;

typedef struct dim3 {
      unsigned x, y, z;
} dim3;

typedef int cudaStream_t;
typedef int cudaEvent_t;

/* Memory. */

cudaError_t cudaMalloc(void** devPtr, size_t size);
cudaError_t cudaFree(void* devptr);
cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, enum cudaMemcpyKind kind);
cudaError_t cudaMemcpyAsync(void* dst, const void* src, size_t count, enum cudaMemcpyKind kind, cudaStream_t stream);

cudaError_t cudaHostAlloc(void** pHost, size_t size, unsigned flags); /*TODO*/
cudaError_t cudaMallocHost(void** ptr, size_t size);
cudaError_t cudaFreeHost(void* ptr);

cudaError_t cudaMemset(void* devPtr, int value, size_t count);
cudaError_t cudaMemsetAsync(void* devPtr, int value, size_t count, cudaStream_t stream);

/* These are nops for now. */
__device__ void __threadfence_block(void); /*TODO*/
__device__ void __threadfence(void); /*TODO*/
__device__ void __threadfence_system(void); /*TODO*/

__device__ void __syncthreads(void);
__device__ int __syncthreads_count(int predicate);
__device__ int __syncthreads_and(int predicate);
__device__ int __syncthreads_or(int predicate);

extern dim3 threadIdx;
extern dim3 blockIdx;
extern dim3 gridDim;
extern dim3 blockDim;
extern int warpSize; /* 32. */

/* Streams. */

cudaError_t cudaStreamCreate(cudaStream_t* pStream);
cudaError_t cudaStreamDestroy(cudaStream_t stream);
cudaError_t cudaStreamQuery(cudaStream_t stream);
cudaError_t cudaStreamSynchronize(cudaStream_t stream);
cudaError_t cudaStreamWaitEvent(cudaStream_t stream);

/* Events. */

cudaError_t cudaEventCreate(cudaEvent_t* event);
cudaError_t cudaEventCreateWithFlags(cudaEvent_t* event, unsigned flags); /*TODO*/
cudaError_t cudaEventDestroy(cudaEvent_t event);
cudaError_t cudaEventQuery(cudaEvent_t event);
cudaError_t cudaEventRecord(cudaEvent_t event, cudaStream_t stream);
cudaError_t cudaEventSynchronize(cudaEvent_t event);
cudaError_t cudaEventElapsedTime(float* ms, cudaEvent_t start, cudaEvent_t end); /*TODO*/

/* Devices. */

//cudaError_t cudaSetDevice(int device);
cudaError_t cudaGetDeviceCount(int* count);
cudaError_t cudaDeviceReset(void); /*TODO*/
//cudaError_t cudaGetDeviceProperties(struct cudaDeviceProp* prop, int device);
cudaError_t cudaDeviceSynchronize(void);

cudaError_t cudaDeviceCanAccessPeer(int* canAccessPeer, int device, int peerDevice); /* Answer: No. */
cudaError_t cudaDeviceDisablePeerAccess(int peerDevice);
cudaError_t cudaDeviceEnablePeerAccess(int peerDevice, unsigned flags);

/* Math. */

__host__ __device__ double asin(double x);
__host__ __device__ double atan(double x);
__host__ __device__ double atan2(double x, double y);
__host__ __device__ double cos(double x);
__host__ __device__ double exp(double x);
__host__ __device__ double floor(double x);
__host__ __device__ double fmod(double x, double y);
__host__ __device__ double log(double x);
__host__ __device__ double sin(double x);
__host__ __device__ double sqrt(double x);
__host__ __device__ double tan(double x);

__host__ __device__ float asinf(float x);
__host__ __device__ float atanf(float x);
__host__ __device__ float atan2f(float x, float y);
__host__ __device__ float cosf(float x);
__host__ __device__ float expf(float x);
__host__ __device__ float floorf(float x);
__host__ __device__ float fmodf(float x, float y);
__host__ __device__ float logf(float x);
__host__ __device__ float sinf(float x);
__host__ __device__ float sqrtf(float x);
__host__ __device__ float tanf(float x);

__device__ float __cosf(float x);
__device__ float __expf(float x);
__device__ float __logf(float x);
__device__ float __sinf(float x);
__device__ float __tanf(float x);

/* The CUDA version of malloc allocates global device memory. */

__device__ void* malloc(size_t size);
__device__ void free(void* ptr);

/* Debugging. */

__device__ int printf(const char * restrict format, ...);
# 5 "/home/chathhorn/gitpub/cuda-sem/cuda-c/cuda-test/guide/b05-sum.cu" 2
typedef bool int;

__device__ unsigned int count = 0;

__shared__ bool isLastBlockDone;

__global__ void sum(const float* array, unsigned int N, float* result) {

      // Each block sums a subset of the input array
      float partialSum = calculatePartialSum(array, N);

      if (threadIdx.x == 0) {
            // Thread 0 of each block stores the partial sum
            // to global memory
            result[blockIdx.x] = partialSum;
            // Thread 0 makes sure its result is visible to
            // all other threads
            __threadfence();
            // Thread 0 of each block signals that it is done
            unsigned int value = atomicInc(&count, gridDim.x);
            // Thread 0 of each block determines if its block is
            // the last block to be done
            isLastBlockDone = (value == (gridDim.x - 1));
      }

      // Synchronize to make sure that each thread reads
      // the correct value of isLastBlockDone
      __syncthreads();
      if (isLastBlockDone) {
            // The last block sums the partial sums
            // stored in result[0 .. gridDim.x-1]

            float totalSum = calculateTotalSum(result);
            if (threadIdx.x == 0) {
                  // Thread 0 of last block stores total sum
                  // to global memory and resets count so that
                  // next kernel call works properly
                  result[0] = totalSum;
                  count = 0;
            }
      }
}
