global sum_kernel(g_odata, g_idata, n, run) {
      int i, tid = threadIdx;

      shared[tid] = *(g_idata + tid);
      syncthreads();

      if (tid < n/2) {
            shared[tid] = shared[tid] + shared[n/2 + tid];
      }

      syncthreads();

      if (tid == 0) {
            for (i = 1; i != n/2; ++i) 
                  shared[0] = shared[0] + shared[i];
            *(g_odata + run) = shared[0];
      }
}

host main() {
      int i, num_elements = 12;

      int nblocks = 1;
      int nthreads = num_elements;
      // nruns should be < num_elements.
      int nruns = 5;

      int h_data = malloc(num_elements);

      print("INPUT: ");
      for(i = 0; i != num_elements; ++i) {
            *(h_data + i) = (11 + i * i) % 7;
            print(" ", *(h_data + i), " ");
      }
      print("\n");

      int d_idata;
      int d_odata;
      cudaMalloc(&d_idata, num_elements);
      cudaMalloc(&d_odata, nruns);

      cudaMemcpy(d_idata, h_data, num_elements, cudaMemcpyHostToDevice);

      print("Running sum of ", num_elements, " elements\n");

      for (i = 0; i != nruns; ++i) {
            sum_kernel<<< nblocks, nthreads, 2 * num_elements, i >>>
                  (d_odata, d_idata, num_elements, i);
      }
      cudaDeviceSynchronize();

      cudaMemcpyAsync(h_data, d_odata, nruns, cudaMemcpyDeviceToHost, 1);

      cudaStreamSynchronize(1);

      print("OUTPUT: ");
      for(i = 0; i != nruns; ++i) {
            print(" ", *(h_data + i), " ");
      }
      print("\n");

      free(h_data);
      cudaFree(d_idata);
      cudaFree(d_odata);
}
